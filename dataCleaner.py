# -*- coding: utf-8 -*-
"""Dataset_cleaner.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_Zz3HNLGIhpQ-TqeuLHxONJLSjpHgEsc
"""

import re
article = open("article_with_garbage.txt", "r")
summary = open("summary_with_garbage.txt", "r")

# Article Standardization
pattern = r"[(A-Z)|(a-z)|(0-9)|\-|!|;|.|‘|’|'|/]+"
lines1 = [re.sub(pattern, '', l) for l in article]
lines1 = [re.sub(' +', ' ', l) for l in lines1]
lines1 = [l.strip() for l in lines1]

# Summary Standardization
pattern = r"[(A-Z)|(a-z)|(0-9)|\-|!|;|.|‘|’|'|/]+"
lines2 = [re.sub(pattern, '', l) for l in summary]
lines2 = [re.sub(' +', ' ', l) for l in lines2]
lines2 = [l.strip() for l in lines2]

# Remove Articles with less then 5 words
sum = []
art = []

for i in range(len(lines1)):
  res = len(lines1[i].split())
  if res>=5:
    art.append(lines1[i])
    sum.append(lines2[i])

# Remove Summaries with less then 3 words
sum1 = []
art1 = []

for i in range(len(sum)):
  res = len(sum[i].split())
  if res>2:
    sum1.append(sum[i])
    art1.append(art[i])    
print(len(art1),len(sum1))

with open('article.txt', 'w') as filehandle:
    for listitem in art1:
        filehandle.write('%s\n' % listitem)

with open('summary.txt', 'w') as filehandle:
    for listitem in sum1:
        filehandle.write('%s\n' % listitem)

